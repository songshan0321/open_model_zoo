models:
  - name: Alexnet

    # list of launchers for your topology.
    launchers:
        # launcher framework (e.g. caffe, dlsdk)
      - framework: dlsdk
        # device for infer (e.g. for dlsdk cpu, gpu, hetero:cpu,gpu ...)
        device: CPU
        # topology IR (*.prototxt for caffe, *.xml for InferenceEngine, etc)
        # path to topology is prefixed with directory, specified in "-m/--models" option
        # If you use dlsdk launcher, you can specify model in source framework format in this case Model Optimizer will be used for getting converted model.
        model: alexnet.xml
        # topology weights binary (*.caffemodel for caffe, *.bin for InferenceEngine)
        weights: alexnet.bin
        # launcher returns raw result, so it should be converted
        # to an appropriate representation with adapter
        adapter: classification
        # batch size
        batch: 1

    # metrics, preprocessing and postprocessing are typically dataset specific, so dataset field
    # specifies data and all other steps required to validate topology
    # there is typically definitions file, which contains options for common datasets and which is merged
    # during evaluation, but since "sample_dataset" is not used anywhere else, this config contains full definition
    datasets:
        # uniquely distinguishable name for dataset
        # note that all other steps are specific for this dataset only
        # if you need to test topology on multiple datasets, you need to specify
        # every step explicitly for each dataset
      - name: dataset
        # directory where input images are searched.
        # prefixed with directory specified in "-s/--source" option
        data_source: dataset/val
        # parameters for annotation conversion to a common annotation representation format.
        annotation_conversion:
          # specified which annotation converter will be used
          #  In order to do this you need to provide your own annotation converter,
          # i.e. implement BaseFormatConverter interface.
          # All annotation converters are stored in accuracy_checker/annotation_converters directory.
          converter: cifar10
          # converter specific parameters.
          # Full range available options you can find in accuracy_checker/annotation_converters/README.md
          # relative paths will be merged with "-s/--source" option
          data_batch_file: lb-cifar/val
          # cifar stores images as binary file, we should convert them to png in first evaluation.
          # Yo do not need to use these options if you have already converted dataset images.
          convert_images: True
          # path to save converted images.
          converted_images_dir: dataset/val

        # list of preprocessing, applied to each image during validation
        # order of entries matters
        preprocessing:
            # resize input image to topology input size
            # you may specify size to which image should be resized
            # via dst_width, dst_height fields
          - type: resize
            size: 256
            aspect_ratio_scale: width
            # central cropping for image.
          - type: crop
            size: 224
            # topology is trained on RGB images, but OpenCV reads in BGR
            # thence it must be converted to RGB
        #   - type: bgr_to_rgb
        #     # dataset mean and standard deviation
        #   - type: normalization
        #     # you may specify precomputed statistics manually or use precomputed values, such as ImageNet as well
        #     mean: (123.675, 116.28, 103.53)
        #     std: (58.395, 57.12, 57.375)

        # list of metrics, calculated on dataset
        metrics:
          - type: accuracy
            top_k: 1
